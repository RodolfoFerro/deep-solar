{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMGZKbz9X9bVVU/iA5+xFNV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodolfoFerro/deep-solar/blob/main/notebooks/Data_exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data exploration\n",
        "\n",
        "> This is an exploratory version, the final version will be uploaded soon.\n",
        "\n",
        "## Current pipeline method\n",
        "\n",
        "At present, the raw data are converted to physics units using a calibration table, summed over the sensor segments, and recast as phase space distribution functions. A variety of ad hoc operations are invoked in order to tweak the background subtraction, isolate the physically relevant sub-range in voltage, and remove transients. Then a Gaussian peak fitting is performed. The parameters of the Gaussian map directly to _(n, w, |v|)_. Finally, the ratios between the signal peak values are fed into a table lookup to estimate the flow angle and complete the velocity vector."
      ],
      "metadata": {
        "id": "oqlZ8kFJnuP9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6d7XNadnmdl"
      },
      "outputs": [],
      "source": [
        "!pip install wget cdflib dtw-python -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Notes:** \n",
        "> - Data from [_Wind dataset_](https://cdaweb.gsfc.nasa.gov/pub/data/wind/mfi/mfi_h2/2022/) is available from 1994 (1994-11-13) to 2022 (2022-09-17).\n",
        "> - Data form [_DSCOVR magnetic field dataset_](https://cdaweb.gsfc.nasa.gov/pub/data/dscovr/h0/mag/2022/) is available from 2015 (2015-06-08) to 2022 (2022-09-17)."
      ],
      "metadata": {
        "id": "3XY4R_m-n84p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "from dtw import dtw\n",
        "from dtw import rabinerJuangStepPattern\n",
        "import cdflib\n",
        "import wget\n",
        "\n",
        "plt.style.use('seaborn')"
      ],
      "metadata": {
        "id": "nUU-msXLn6YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_date = '2022-09-16'\n",
        "date = re.sub('-', '',  raw_date)\n",
        "\n",
        "wind_url = f'https://cdaweb.gsfc.nasa.gov/pub/data/wind/mfi/mfi_h2/2022/wi_h2_mfi_{date}_v03.cdf'\n",
        "mfield_url = f'https://cdaweb.gsfc.nasa.gov/pub/data/dscovr/h0/mag/2022/dscovr_h0_mag_{date}_v01.cdf'\n",
        "\n",
        "wind_filename = wget.download(wind_url)\n",
        "mfield_filename = wget.download(mfield_url)\n",
        "\n",
        "print(f'Files from {raw_date} to be used:')\n",
        "print(' wind ->', wind_filename)\n",
        "print(' magnetic field ->', mfield_filename)"
      ],
      "metadata": {
        "id": "vD_pC5vLn_oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wind_cdf_data = cdflib.cdf_to_xarray(wind_filename, to_datetime=True, fillval_to_nan=True)\n",
        "wind_cdf_data"
      ],
      "metadata": {
        "id": "aAeWx47toB0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wind_data = wind_cdf_data['BGSE'].to_pandas()\n",
        "wind_data.columns = ['x', 'y', 'z']\n",
        "wind_data['BF1'] = wind_cdf_data['BF1'].to_pandas()\n",
        "\n",
        "print('Wind data:')\n",
        "wind_data"
      ],
      "metadata": {
        "id": "L5Y4IcSqoPK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wind_data['BF1'].plot()"
      ],
      "metadata": {
        "id": "UzbRxAwYoVLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wind_data['norm'] = np.linalg.norm(wind_data[['x', 'y', 'z']].values, axis=1)\n",
        "wind_data"
      ],
      "metadata": {
        "id": "JYVOGr703jZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "wind_data_model = MinMaxScaler().fit_transform(wind_data[['norm', 'BF1']])"
      ],
      "metadata": {
        "id": "BlSMtefCqp-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wind_data_model"
      ],
      "metadata": {
        "id": "pUbP8TlNq_qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model and performance\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, losses\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "data_length = 2\n",
        "\n",
        "w_train, w_test = train_test_split(wind_data_model, test_size=0.2, random_state=42)\n",
        "\n",
        "input = tf.keras.layers.Input(shape=(data_length,))\n",
        "\n",
        "# Encoder layers\n",
        "encoder = tf.keras.Sequential([\n",
        "  layers.Dense(16, activation='relu'),\n",
        "  layers.Dense(8, activation='relu'),\n",
        "  layers.Dense(4, activation='relu')])(input)\n",
        "\n",
        "# Decoder layers\n",
        "decoder = tf.keras.Sequential([\n",
        "      layers.Dense(8, activation='relu'),\n",
        "      layers.Dense(16, activation='relu'),\n",
        "      layers.Dense(data_length, activation='sigmoid')])(encoder)\n",
        "\n",
        "# Create the autoencoder\n",
        "autoencoder = tf.keras.Model(inputs=input, outputs=decoder)"
      ],
      "metadata": {
        "id": "Ykk8kDuxoeFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the autoencoder\n",
        "autoencoder.compile(optimizer='adam', loss='msle',  metrics=['mse'])\n",
        "\n",
        "# Fit the autoencoder\n",
        "history = autoencoder.fit(\n",
        "    w_train,\n",
        "    w_train,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    validation_data=(w_test, w_test))"
      ],
      "metadata": {
        "id": "oyTnbY3Ap_No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSLE Loss')\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GiAWeZMVqJX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_threshold(model, x_train_scaled):\n",
        "    reconstructions = model.predict(x_train_scaled)\n",
        "    # provides losses of individual instances\n",
        "    reconstruction_errors = tf.keras.losses.msle(reconstructions, x_train_scaled)\n",
        "    # threshold for anomaly scores\n",
        "    threshold = np.mean(reconstruction_errors.numpy()) \\\n",
        "        + 3 * np.std(reconstruction_errors.numpy())\n",
        "    return threshold\n",
        "\n",
        "def get_predictions(model, x_test_scaled, threshold):\n",
        "    predictions = model.predict(x_test_scaled)\n",
        "    # provides losses of individual instances\n",
        "    errors = tf.keras.losses.msle(predictions, x_test_scaled)\n",
        "    # 0 = anomaly, 1 = normal\n",
        "    anomaly_mask = pd.Series(errors) > threshold\n",
        "    preds = anomaly_mask.map(lambda x: 1 if x == True else 0)\n",
        "    return errors, preds"
      ],
      "metadata": {
        "id": "FlGX9mkltcrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = find_threshold(autoencoder, w_train)\n",
        "print(f\"Threshold: {threshold}\")"
      ],
      "metadata": {
        "id": "e1d_UcPKtpLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors, predictions = get_predictions(autoencoder, w_test, threshold)"
      ],
      "metadata": {
        "id": "VBFGscD66QdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(20, 5))\n",
        "plt.plot(errors[:1000])\n",
        "plt.axhline(y=threshold, color='r', linestyle='-')"
      ],
      "metadata": {
        "id": "R4Gjt8H0vHRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(predictions),  sum(predictions)"
      ],
      "metadata": {
        "id": "DOEvDAfV6mSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructions = autoencoder.predict(w_train)\n",
        "reconstruction_errors = tf.keras.losses.msle(reconstructions, w_train)"
      ],
      "metadata": {
        "id": "7G-9GaSxIvlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_train[0], reconstructions[0], reconstruction_errors[0].numpy()"
      ],
      "metadata": {
        "id": "Z1os2P-wJ82P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the histogram of the data\n",
        "n, bins, patches = plt.hist(reconstruction_errors[:100], density=True)\n",
        "\n",
        "\n",
        "plt.xlabel('Smarts')\n",
        "plt.ylabel('Probability')\n",
        "plt.title('Histogram of reconstructions')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cdD-1X5lJjv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the histogram of the data\n",
        "n, bins, patches = plt.hist(reconstructions, density=True, facecolor='g', alpha=0.75)\n",
        "\n",
        "\n",
        "plt.xlabel('Smarts')\n",
        "plt.ylabel('Probability')\n",
        "plt.title('Histogram of reconstructions')\n",
        "plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$')\n",
        "plt.xlim(40, 160)\n",
        "plt.ylim(0, 0.03)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eeibw0tVJHYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proposals\n",
        "\n",
        "- Recurrent neural network\n",
        "- ARIMA Models"
      ],
      "metadata": {
        "id": "h_tMXGH4ygwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "x = np.arange(50, 450)\n",
        "\n",
        "fig = make_subplots(rows=2, cols=1)\n",
        "fig.append_trace(go.Scatter(x=x, y=w_train[50:450, 1], line=dict(color='royalblue', width=4, dash='dot')), row=1, col=1)\n",
        "fig.append_trace(go.Scatter(x=x, y=reconstructions[50:450, 1]), row=1, col=1)\n",
        "fig.append_trace(go.Scatter(x=x, y=reconstruction_errors[50:450]), row=2, col=1)\n",
        "fig.add_hline(y=threshold, row=2, col=1)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "JN0Kb0hZLnKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4RUiE6syKfaI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}